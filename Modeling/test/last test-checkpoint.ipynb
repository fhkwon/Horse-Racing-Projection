{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "ad3fc476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 라이브러리\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 시각화 라이브러리 \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 모델 평가 라이브러리\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "\n",
    "# 전처리 라이브러리\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 모델링 라이브러리\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost \n",
    "\n",
    "# 모델 파라미터 \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import optuna\n",
    "\n",
    "# 모델 저장\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "# 기본 설정\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f34b5be",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64ed8263",
   "metadata": {},
   "outputs": [],
   "source": [
    "hores_path = \"full_df.csv\"\n",
    "data_DF = pd.read_csv (hores_path, encoding=\"cp949\")\n",
    "data_DF.drop(columns = \"Unnamed: 0\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a25c4633",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_DF = data_DF.drop(columns = [\"번호\", \"순위\", \"출전두수\", \"기록\", \"경주번호\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f34ab63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF모델 0번째 검증 precision : 0.8057\n",
      "RF모델 1번째 검증 precision : 0.8305\n",
      "RF모델 2번째 검증 precision : 0.7759\n",
      "RF모델 3번째 검증 precision : 0.7834\n",
      "RF모델 4번째 검증 precision : 0.8596\n",
      "RF 평균 precision :  0.8110346885017904\n"
     ]
    }
   ],
   "source": [
    "# RandomForestClassifier \n",
    "rf = RandomForestClassifier(n_jobs=-1, random_state = 29)\n",
    "sk_rf = cross_socre(rf)\n",
    "for idx, score in enumerate(sk_rf):\n",
    "    print(\"RF모델 {0}번째 검증 precision : {1:.4f}\".format(idx,score))\n",
    "print(\"RF 평균 precision : \", sk_rf.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5e5dd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data_DF.drop(columns = \"target 순위\")\n",
    "y = data_DF[\"target 순위\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd63b567",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, random_state=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f18afb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, random_state= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "652ac2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_socre(model):\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=kfold, scoring=\"precision\")\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "85299a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-18 14:44:48,905]\u001b[0m A new study created in memory with name: no-name-42efbb42-e21a-4e01-80de-708b8d4b5128\u001b[0m\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2022-11-18 14:44:51,016]\u001b[0m Trial 0 finished with value: 0.0 and parameters: {'n_estimators': 89, 'max_depth': 2}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2022-11-18 14:44:52,671]\u001b[0m Trial 1 finished with value: 0.0 and parameters: {'n_estimators': 59, 'max_depth': 2}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-11-18 14:44:53,896]\u001b[0m Trial 2 finished with value: 0.6408444947494184 and parameters: {'n_estimators': 8, 'max_depth': 8}. Best is trial 2 with value: 0.6408444947494184.\u001b[0m\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2022-11-18 14:44:54,949]\u001b[0m Trial 3 finished with value: 0.0 and parameters: {'n_estimators': 7, 'max_depth': 3}. Best is trial 2 with value: 0.6408444947494184.\u001b[0m\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2022-11-18 14:44:58,296]\u001b[0m Trial 4 finished with value: 0.0 and parameters: {'n_estimators': 100, 'max_depth': 5}. Best is trial 2 with value: 0.6408444947494184.\u001b[0m\n",
      "\u001b[32m[I 2022-11-18 14:45:02,972]\u001b[0m Trial 5 finished with value: 0.8398252344416027 and parameters: {'n_estimators': 98, 'max_depth': 9}. Best is trial 5 with value: 0.8398252344416027.\u001b[0m\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2022-11-18 14:45:04,454]\u001b[0m Trial 6 finished with value: 0.0 and parameters: {'n_estimators': 24, 'max_depth': 4}. Best is trial 5 with value: 0.8398252344416027.\u001b[0m\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2022-11-18 14:45:06,769]\u001b[0m Trial 7 finished with value: 0.0 and parameters: {'n_estimators': 99, 'max_depth': 2}. Best is trial 5 with value: 0.8398252344416027.\u001b[0m\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2022-11-18 14:45:08,094]\u001b[0m Trial 8 finished with value: 0.0 and parameters: {'n_estimators': 31, 'max_depth': 1}. Best is trial 5 with value: 0.8398252344416027.\u001b[0m\n",
      "\u001b[32m[I 2022-11-18 14:45:12,274]\u001b[0m Trial 9 finished with value: 0.8376087277016069 and parameters: {'n_estimators': 92, 'max_depth': 9}. Best is trial 5 with value: 0.8398252344416027.\u001b[0m\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2022-11-18 14:45:15,240]\u001b[0m Trial 10 finished with value: 0.6833333333333333 and parameters: {'n_estimators': 69, 'max_depth': 7}. Best is trial 5 with value: 0.8398252344416027.\u001b[0m\n",
      "\u001b[32m[I 2022-11-18 14:45:19,252]\u001b[0m Trial 11 finished with value: 0.8136923560129914 and parameters: {'n_estimators': 80, 'max_depth': 10}. Best is trial 5 with value: 0.8398252344416027.\u001b[0m\n",
      "\u001b[32m[I 2022-11-18 14:45:23,235]\u001b[0m Trial 12 finished with value: 0.8059674525680718 and parameters: {'n_estimators': 76, 'max_depth': 10}. Best is trial 5 with value: 0.8398252344416027.\u001b[0m\n",
      "\u001b[32m[I 2022-11-18 14:45:26,125]\u001b[0m Trial 13 finished with value: 0.7937820512820513 and parameters: {'n_estimators': 55, 'max_depth': 8}. Best is trial 5 with value: 0.8398252344416027.\u001b[0m\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2022-11-18 14:45:29,665]\u001b[0m Trial 14 finished with value: 0.4 and parameters: {'n_estimators': 88, 'max_depth': 7}. Best is trial 5 with value: 0.8398252344416027.\u001b[0m\n",
      "\u001b[32m[I 2022-11-18 14:45:32,272]\u001b[0m Trial 15 finished with value: 0.6682906530776714 and parameters: {'n_estimators': 39, 'max_depth': 9}. Best is trial 5 with value: 0.8398252344416027.\u001b[0m\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2022-11-18 14:45:35,085]\u001b[0m Trial 16 finished with value: 0.3 and parameters: {'n_estimators': 67, 'max_depth': 6}. Best is trial 5 with value: 0.8398252344416027.\u001b[0m\n",
      "\u001b[32m[I 2022-11-18 14:45:39,005]\u001b[0m Trial 17 finished with value: 0.8250210084033613 and parameters: {'n_estimators': 88, 'max_depth': 9}. Best is trial 5 with value: 0.8398252344416027.\u001b[0m\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2022-11-18 14:45:41,070]\u001b[0m Trial 18 finished with value: 0.3333333333333333 and parameters: {'n_estimators': 46, 'max_depth': 6}. Best is trial 5 with value: 0.8398252344416027.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-18 14:45:45,075]\u001b[0m Trial 19 finished with value: 0.7870291146761735 and parameters: {'n_estimators': 79, 'max_depth': 9}. Best is trial 5 with value: 0.8398252344416027.\u001b[0m\n",
      "\u001b[32m[I 2022-11-18 14:45:49,254]\u001b[0m Trial 20 finished with value: 0.7778571428571428 and parameters: {'n_estimators': 100, 'max_depth': 8}. Best is trial 5 with value: 0.8398252344416027.\u001b[0m\n",
      "\u001b[32m[I 2022-11-18 14:45:53,637]\u001b[0m Trial 21 finished with value: 0.8140289449112978 and parameters: {'n_estimators': 90, 'max_depth': 9}. Best is trial 5 with value: 0.8398252344416027.\u001b[0m\n",
      "\u001b[32m[I 2022-11-18 14:45:57,623]\u001b[0m Trial 22 finished with value: 0.817249373433584 and parameters: {'n_estimators': 89, 'max_depth': 10}. Best is trial 5 with value: 0.8398252344416027.\u001b[0m\n",
      "\u001b[32m[I 2022-11-18 14:46:00,547]\u001b[0m Trial 23 finished with value: 0.85 and parameters: {'n_estimators': 67, 'max_depth': 7}. Best is trial 23 with value: 0.85.\u001b[0m\n",
      "\u001b[32m[I 2022-11-18 14:46:03,660]\u001b[0m Trial 24 finished with value: 0.85 and parameters: {'n_estimators': 67, 'max_depth': 7}. Best is trial 23 with value: 0.85.\u001b[0m\n",
      "\u001b[32m[I 2022-11-18 14:46:06,526]\u001b[0m Trial 25 finished with value: 0.85 and parameters: {'n_estimators': 64, 'max_depth': 7}. Best is trial 23 with value: 0.85.\u001b[0m\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2022-11-18 14:46:09,000]\u001b[0m Trial 26 finished with value: 0.0 and parameters: {'n_estimators': 64, 'max_depth': 5}. Best is trial 23 with value: 0.85.\u001b[0m\n",
      "\u001b[32m[I 2022-11-18 14:46:11,530]\u001b[0m Trial 27 finished with value: 0.6833333333333333 and parameters: {'n_estimators': 48, 'max_depth': 7}. Best is trial 23 with value: 0.85.\u001b[0m\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2022-11-18 14:46:14,006]\u001b[0m Trial 28 finished with value: 0.2 and parameters: {'n_estimators': 58, 'max_depth': 6}. Best is trial 23 with value: 0.85.\u001b[0m\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2022-11-18 14:46:17,510]\u001b[0m Trial 29 finished with value: 0.7333333333333333 and parameters: {'n_estimators': 73, 'max_depth': 7}. Best is trial 23 with value: 0.85.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def rf_objective (trial):\n",
    "    params = {\n",
    "      \"n_estimators\" : trial.suggest_int(\"n_estimators\", 1, 100),\n",
    "      \"max_depth\" : trial.suggest_int(\"max_depth\", 1, 10),\n",
    "             }\n",
    "    rf = RandomForestClassifier(n_jobs=-1, random_state = 100, **params)\n",
    "    socres = cross_socre(rf)\n",
    "    rf_score = socres.mean()\n",
    "    return rf_score\n",
    "rf_study = optuna.create_study(direction = \"maximize\")\n",
    "rf_study.optimize(rf_objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "5dce26e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value : [0.85]\n",
      "params : {'n_estimators': 67, 'max_depth': 7}\n"
     ]
    }
   ],
   "source": [
    "print(\"value :\", rf_study.best_trial.values)\n",
    "print(\"params :\", rf_study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "9211106f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8253968253968254\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier (n_estimators=60, max_depth = 10, random_state=10, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "print(precision_score(y_test, rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "578049cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_path = \"real_df(classifier).csv\"\n",
    "real_df = pd.read_csv(real_path, encoding=\"cp949\")\n",
    "real_df.drop(columns = \"Unnamed: 0\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "97f48f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# real_df = real_df.drop(columns = \"경주번호\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "b713eb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = real_df.drop(columns =[\"target 순위\"])\n",
    "y = real_df[\"target 순위\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "0dec5a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "racing_1 = real_df[real_df[\"경주번호\"] == 2022111311]\n",
    "racing_2 = real_df[real_df[\"경주번호\"] == 202211135]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "5823c067",
   "metadata": {},
   "outputs": [],
   "source": [
    "racing_1 = racing_1.drop(columns = \"경주번호\", axis=1)\n",
    "racing_2 = racing_2.drop(columns = \"경주번호\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "133a0623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF 정밀도: 0.667\n",
      "예측 : [0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0]\n",
      "실제 : [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# 1경기 \n",
    "X_Real_horse_1 = racing_1.drop(columns =[\"target 순위\"])\n",
    "y_Real_horse_1 = racing_1[\"target 순위\"]\n",
    "\n",
    "# 1경기 수정\n",
    "new_1_rf = pd.DataFrame(rf_model.predict_proba(X_Real_horse_1))\n",
    "new_1_rf[\"y\"] = rf_model.predict(X_Real_horse_1)\n",
    "new_1_rf[\"y\"]  = new_1_rf[0].apply(lambda x : 0 if x > 0.65 else 1)\n",
    "\n",
    "# 1경기 모델 \n",
    "score = precision_score(new_1_rf[\"y\"], y_Real_horse_1)\n",
    "print('RF 정밀도: {score:.3f}'.format(score=score))\n",
    "print(\"예측 :\", list(new_1_rf[\"y\"]))\n",
    "print(\"실제 :\", list(y_Real_horse_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "7866d2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RF_Model 클래스 값 예측\n",
      " [[0.6529799  0.3470201  0.        ]\n",
      " [0.63673402 0.36326598 0.        ]\n",
      " [0.64282397 0.35717603 0.        ]\n",
      " [0.52895972 0.47104028 0.        ]\n",
      " [0.6351036  0.3648964  0.        ]\n",
      " [0.66376361 0.33623639 0.        ]\n",
      " [0.68696528 0.31303472 0.        ]\n",
      " [0.74996707 0.25003293 0.        ]\n",
      " [0.63875113 0.36124887 0.        ]\n",
      " [0.72577039 0.27422961 0.        ]\n",
      " [0.71431365 0.28568635 0.        ]\n",
      " [0.71015473 0.28984527 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# 예측 확률 proba \n",
    "pred_proba = rf_model.predict_proba(X_Real_horse_1)\n",
    "pred = rf_model.predict(X_Real_horse_1)\n",
    "pred_proba_result = np.concatenate([pred_proba,pred.reshape(-1,1)],axis=1)\n",
    "print('  RF_Model 클래스 값 예측\\n',pred_proba_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "66240a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF 정밀도: 0.667\n",
      "예측 : [0, 1, 1, 1, 1, 0, 0, 0, 1]\n",
      "실제 : [1, 1, 1, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# 2경기 \n",
    "X_Real_horse_2 = racing_2.drop(columns =[\"target 순위\"])\n",
    "y_Real_horse_2 = racing_2[\"target 순위\"]\n",
    "\n",
    "# 2경기 수정\n",
    "new_2_rf = pd.DataFrame(rf_model.predict_proba(X_Real_horse_2))\n",
    "new_2_rf[\"y\"] = rf_model.predict(X_Real_horse_2)\n",
    "new_2_rf[\"y\"]  = new_1_rf[0].apply(lambda x : 0 if x > 0.65 else 1)\n",
    "\n",
    "# 2경기 모델 \n",
    "score = precision_score(new_2_rf[\"y\"], y_Real_horse_2)\n",
    "print('RF 정밀도: {score:.3f}'.format(score=score))\n",
    "print(\"예측 :\", list(new_2_rf[\"y\"]))\n",
    "print(\"실제 :\", list(y_Real_horse_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876ea7fe",
   "metadata": {},
   "source": [
    "# XGBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "ec529417",
   "metadata": {},
   "outputs": [],
   "source": [
    "hores_path = \"full_df.csv\"\n",
    "data_DF = pd.read_csv (hores_path, encoding=\"cp949\")\n",
    "data_DF.drop(columns = \"Unnamed: 0\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "ddc75996",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_DF = data_DF.drop(columns = [\"번호\", \"순위\", \"출전두수\", \"기록\", \"경주번호\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "60930c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB모델 0번째 검증 precision:0.7530\n",
      "XGB모델 1번째 검증 precision:0.7919\n",
      "XGB모델 2번째 검증 precision:0.7421\n",
      "XGB모델 3번째 검증 precision:0.7424\n",
      "XGB모델 4번째 검증 precision:0.8145\n",
      "XGB 평균 precision: 0.7687914034284009\n"
     ]
    }
   ],
   "source": [
    "# XGBClassifier \n",
    "xgbc = XGBClassifier(n_jobs = -1, random_state=1234, use_label_encoder=False)\n",
    "scores = cross_socre(xgbc)\n",
    "for idx, score in enumerate(scores):\n",
    "    print(\"XGB모델 {0}번째 검증 precision:{1:.4f}\".format(idx,score))\n",
    "print(\"XGB 평균 precision:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "1a6b8e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data_DF.drop(columns = \"target 순위\")\n",
    "y = data_DF[\"target 순위\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "392f3b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, random_state= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "c2a97190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgbc_objective(trial):\n",
    "    params = {\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10),\n",
    "        \"learning_rate\": trial.suggest_uniform('learning_rate', 0.1, 1.0),\n",
    "        'n_estimators': trial.suggest_int(\"n_estimators\", 100, 1000),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0.1, 1.0, log=True),\n",
    "    }\n",
    "    xgbc = XGBClassifier(**params,n_jobs = -1, random_state=1234,\n",
    "                         use_label_encoder=False, objective = \"binary:logistic\",\n",
    "                        eval_metric = \"error\")\n",
    "    scores = cross_val_score(xgbc, X_train, y_train, cv=kfold, scoring=\"precision\")\n",
    "    pre_mean = scores.mean()\n",
    "    return pre_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "8d5dc1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-18 15:15:22,140]\u001b[0m A new study created in memory with name: no-name-baf8de86-c0d1-4adc-815a-58cf39b6075f\u001b[0m\n",
      "C:\\Users\\sjm24\\AppData\\Local\\Temp\\ipykernel_3976\\3436621036.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  \"learning_rate\": trial.suggest_uniform('learning_rate', 0.1, 1.0),\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "\u001b[32m[I 2022-11-18 15:15:41,256]\u001b[0m Trial 0 finished with value: 0.7674810768313225 and parameters: {'max_depth': 4, 'learning_rate': 0.4386165009455699, 'n_estimators': 441, 'gamma': 0.20718251704016735}. Best is trial 0 with value: 0.7674810768313225.\u001b[0m\n",
      "C:\\Users\\sjm24\\AppData\\Local\\Temp\\ipykernel_3976\\3436621036.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  \"learning_rate\": trial.suggest_uniform('learning_rate', 0.1, 1.0),\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "\u001b[32m[I 2022-11-18 15:16:12,550]\u001b[0m Trial 1 finished with value: 0.7323115993128934 and parameters: {'max_depth': 10, 'learning_rate': 0.48254703138183186, 'n_estimators': 240, 'gamma': 0.343531764574765}. Best is trial 0 with value: 0.7674810768313225.\u001b[0m\n",
      "C:\\Users\\sjm24\\AppData\\Local\\Temp\\ipykernel_3976\\3436621036.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  \"learning_rate\": trial.suggest_uniform('learning_rate', 0.1, 1.0),\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "\u001b[32m[I 2022-11-18 15:16:51,262]\u001b[0m Trial 2 finished with value: 0.7505676491407993 and parameters: {'max_depth': 6, 'learning_rate': 0.6731969535017547, 'n_estimators': 415, 'gamma': 0.17017822643942157}. Best is trial 0 with value: 0.7674810768313225.\u001b[0m\n",
      "C:\\Users\\sjm24\\AppData\\Local\\Temp\\ipykernel_3976\\3436621036.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  \"learning_rate\": trial.suggest_uniform('learning_rate', 0.1, 1.0),\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "\u001b[32m[I 2022-11-18 15:17:12,668]\u001b[0m Trial 3 finished with value: 0.7399193836988159 and parameters: {'max_depth': 4, 'learning_rate': 0.6895356694640168, 'n_estimators': 404, 'gamma': 0.32998755332826163}. Best is trial 0 with value: 0.7674810768313225.\u001b[0m\n",
      "C:\\Users\\sjm24\\AppData\\Local\\Temp\\ipykernel_3976\\3436621036.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  \"learning_rate\": trial.suggest_uniform('learning_rate', 0.1, 1.0),\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "\u001b[32m[I 2022-11-18 15:17:38,170]\u001b[0m Trial 4 finished with value: 0.7110494465797121 and parameters: {'max_depth': 2, 'learning_rate': 0.9394577915427405, 'n_estimators': 927, 'gamma': 0.11714497982704994}. Best is trial 0 with value: 0.7674810768313225.\u001b[0m\n",
      "C:\\Users\\sjm24\\AppData\\Local\\Temp\\ipykernel_3976\\3436621036.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  \"learning_rate\": trial.suggest_uniform('learning_rate', 0.1, 1.0),\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "\u001b[32m[I 2022-11-18 15:17:47,688]\u001b[0m Trial 5 finished with value: 0.6544987008504827 and parameters: {'max_depth': 2, 'learning_rate': 0.7930522677840571, 'n_estimators': 341, 'gamma': 0.10868704541200104}. Best is trial 0 with value: 0.7674810768313225.\u001b[0m\n",
      "C:\\Users\\sjm24\\AppData\\Local\\Temp\\ipykernel_3976\\3436621036.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  \"learning_rate\": trial.suggest_uniform('learning_rate', 0.1, 1.0),\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "\u001b[32m[I 2022-11-18 15:18:29,944]\u001b[0m Trial 6 finished with value: 0.7638769739342219 and parameters: {'max_depth': 9, 'learning_rate': 0.2802468444291821, 'n_estimators': 384, 'gamma': 0.5950907131444995}. Best is trial 0 with value: 0.7674810768313225.\u001b[0m\n",
      "C:\\Users\\sjm24\\AppData\\Local\\Temp\\ipykernel_3976\\3436621036.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  \"learning_rate\": trial.suggest_uniform('learning_rate', 0.1, 1.0),\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "\u001b[32m[I 2022-11-18 15:19:50,581]\u001b[0m Trial 7 finished with value: 0.7454078657983727 and parameters: {'max_depth': 7, 'learning_rate': 0.5446735404338524, 'n_estimators': 958, 'gamma': 0.4485528254365341}. Best is trial 0 with value: 0.7674810768313225.\u001b[0m\n",
      "C:\\Users\\sjm24\\AppData\\Local\\Temp\\ipykernel_3976\\3436621036.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  \"learning_rate\": trial.suggest_uniform('learning_rate', 0.1, 1.0),\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "\u001b[32m[I 2022-11-18 15:20:55,897]\u001b[0m Trial 8 finished with value: 0.7973080690771063 and parameters: {'max_depth': 8, 'learning_rate': 0.1680483230924148, 'n_estimators': 580, 'gamma': 0.168726487743825}. Best is trial 8 with value: 0.7973080690771063.\u001b[0m\n",
      "C:\\Users\\sjm24\\AppData\\Local\\Temp\\ipykernel_3976\\3436621036.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  \"learning_rate\": trial.suggest_uniform('learning_rate', 0.1, 1.0),\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "\u001b[32m[I 2022-11-18 15:21:19,025]\u001b[0m Trial 9 finished with value: 0.7912317437587498 and parameters: {'max_depth': 4, 'learning_rate': 0.20238081002359687, 'n_estimators': 442, 'gamma': 0.24531034863147955}. Best is trial 8 with value: 0.7973080690771063.\u001b[0m\n",
      "C:\\Users\\sjm24\\AppData\\Local\\Temp\\ipykernel_3976\\3436621036.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  \"learning_rate\": trial.suggest_uniform('learning_rate', 0.1, 1.0),\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "\u001b[32m[I 2022-11-18 15:22:24,608]\u001b[0m Trial 10 finished with value: 0.787403185012977 and parameters: {'max_depth': 8, 'learning_rate': 0.10744033787999797, 'n_estimators': 700, 'gamma': 0.991295844678939}. Best is trial 8 with value: 0.7973080690771063.\u001b[0m\n",
      "C:\\Users\\sjm24\\AppData\\Local\\Temp\\ipykernel_3976\\3436621036.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  \"learning_rate\": trial.suggest_uniform('learning_rate', 0.1, 1.0),\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "\u001b[33m[W 2022-11-18 15:22:55,953]\u001b[0m Trial 11 failed because of the following error: KeyboardInterrupt()\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\sjm24\\AppData\\Local\\Temp\\ipykernel_3976\\3436621036.py\", line 11, in xgbc_objective\n",
      "    scores = cross_val_score(xgbc, X_train, y_train, cv=kfold, scoring=\"precision\")\n",
      "  File \"C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 509, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "  File \"C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 267, in cross_validate\n",
      "    results = parallel(\n",
      "  File \"C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1046, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\sjm24\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3976\\510475420.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mxgbc_study\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"maximize\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mxgbc_study\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgbc_objective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\optuna\\study\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    417\u001b[0m         \"\"\"\n\u001b[0;32m    418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 419\u001b[1;33m         _optimize(\n\u001b[0m\u001b[0;32m    420\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m             _optimize_sequential(\n\u001b[0m\u001b[0;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m             \u001b[0mfrozen_trial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m             \u001b[1;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m     ):\n\u001b[1;32m--> 234\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m             \u001b[0mvalue_or_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m             \u001b[1;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3976\\3436621036.py\u001b[0m in \u001b[0;36mxgbc_objective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m      9\u001b[0m                          \u001b[0muse_label_encoder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobjective\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"binary:logistic\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                         eval_metric = \"error\")\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgbc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"precision\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mpre_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpre_mean\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    507\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 509\u001b[1;33m     cv_results = cross_validate(\n\u001b[0m\u001b[0;32m    510\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;31m# independent, and that it is pickle-able.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m     results = parallel(\n\u001b[0m\u001b[0;32m    268\u001b[0m         delayed(_fit_and_score)(\n\u001b[0;32m    269\u001b[0m             \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1046\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1047\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    678\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 680\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 620\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    621\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1514\u001b[0m             )\n\u001b[0;32m   1515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1516\u001b[1;33m             self._Booster = train(\n\u001b[0m\u001b[0;32m   1517\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1518\u001b[0m                 \u001b[0mtrain_dmatrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 620\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    621\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1917\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[0;32m   1919\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1920\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xgbc_study = optuna.create_study(direction=\"maximize\")\n",
    "xgbc_study.optimize(xgbc_objective, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "6eb23f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value : [0.7973080690771063]\n",
      "params : {'max_depth': 8, 'learning_rate': 0.1680483230924148, 'n_estimators': 580, 'gamma': 0.168726487743825}\n"
     ]
    }
   ],
   "source": [
    "print(\"value :\", xgbc_study.best_trial.values)\n",
    "print(\"params :\", xgbc_study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "0eff2b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8591772151898734"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 찾은 최적의 값으로 모델을 재학습\n",
    "opt_xgbc = XGBClassifier(n_jobs = -1,\n",
    "                        random_state = 1234,\n",
    "                        n_estimators = 579,\n",
    "                        learning_rate = 0.1,\n",
    "                        max_depth = 7 ,\n",
    "                        gamma = 0.1)\n",
    "opt_xgbc.fit(X_train, y_train)\n",
    "precision_score(y_test, opt_xgbc.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "092691d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_path = \"real_df(classifier).csv\"\n",
    "real_df = pd.read_csv(real_path, encoding=\"cp949\")\n",
    "real_df.drop(columns = \"Unnamed: 0\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "74ba5e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "racing_1 = real_df[real_df[\"경주번호\"] == 2022111311]\n",
    "racing_2 = real_df[real_df[\"경주번호\"] == 202211135]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "ea7ac3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "racing_1 = racing_1.drop(columns = \"경주번호\", axis=1)\n",
    "racing_2 = racing_2.drop(columns = \"경주번호\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "12f8fc2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF 정밀도: 0.000\n",
      "예측 : [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "실제 : [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# 1경기 \n",
    "X_Real_horse_1 = racing_1.drop(columns =[\"target 순위\"])\n",
    "y_Real_horse_1 = racing_1[\"target 순위\"]\n",
    "\n",
    "# 1경기 수정\n",
    "new_1_rf = pd.DataFrame(opt_xgbc.predict_proba(X_Real_horse_1))\n",
    "new_1_rf[\"y\"] = opt_xgbc.predict(X_Real_horse_1)\n",
    "new_1_rf[\"y\"]  = new_1_rf[0].apply(lambda x : 0 if x > 0.65 else 1)\n",
    "\n",
    "# 1경기 모델 \n",
    "score = precision_score(new_1_rf[\"y\"], y_Real_horse_1)\n",
    "print('RF 정밀도: {score:.3f}'.format(score=score))\n",
    "print(\"예측 :\", list(new_1_rf[\"y\"]))\n",
    "print(\"실제 :\", list(y_Real_horse_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "152905e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  XGB_Model 클래스 값 예측\n",
      " [[0.96752179 0.03247821 0.        ]\n",
      " [0.96414453 0.03585546 0.        ]\n",
      " [0.98816001 0.01183998 0.        ]\n",
      " [0.72009754 0.27990249 0.        ]\n",
      " [0.88851017 0.11148982 0.        ]\n",
      " [0.91069603 0.08930398 0.        ]\n",
      " [0.79159111 0.20840888 0.        ]\n",
      " [0.86727172 0.13272826 0.        ]\n",
      " [0.75382328 0.2461767  0.        ]\n",
      " [0.9107694  0.08923061 0.        ]\n",
      " [0.62269926 0.37730071 0.        ]\n",
      " [0.65799272 0.34200728 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# 예측 확률 proba \n",
    "pred_proba = opt_xgbc.predict_proba(X_Real_horse_1)\n",
    "pred = opt_xgbc.predict(X_Real_horse_1)\n",
    "pred_proba_result = np.concatenate([pred_proba,pred.reshape(-1,1)],axis=1)\n",
    "print('  XGB_Model 클래스 값 예측\\n',pred_proba_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51fd3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2경기 \n",
    "X_Real_horse_2 = racing_2.drop(columns =[\"target 순위\"])\n",
    "y_Real_horse_2 = racing_2[\"target 순위\"]\n",
    "\n",
    "# 2경기 수정\n",
    "new_2_rf = pd.DataFrame(opt_xgbc.predict_proba(X_Real_horse_2))\n",
    "new_2_rf[\"y\"] = opt_xgbc.predict(X_Real_horse_2)\n",
    "new_2_rf[\"y\"]  = new_1_rf[0].apply(lambda x : 0 if x > 0.65 else 1)\n",
    "\n",
    "# 2경기 모델 \n",
    "score = precision_score(new_2_rf[\"y\"], y_Real_horse_2)\n",
    "print('RF 정밀도: {score:.3f}'.format(score=score))\n",
    "print(\"예측 :\", list(new_2_rf[\"y\"]))\n",
    "print(\"실제 :\", list(y_Real_horse_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdb56e5",
   "metadata": {},
   "source": [
    "# LightGbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "6c5f469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hores_path = \"full_df.csv\"\n",
    "data_DF = pd.read_csv (hores_path, encoding=\"cp949\")\n",
    "data_DF.drop(columns = \"Unnamed: 0\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "0ef7039e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_DF = data_DF.drop(columns = [\"번호\", \"순위\", \"출전두수\", \"기록\", \"경주번호\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "d1b3d893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGB모델 0번째 검증 precision:0.7490\n",
      "LGB모델 1번째 검증 precision:0.7828\n",
      "LGB모델 2번째 검증 precision:0.7621\n",
      "LGB모델 3번째 검증 precision:0.7125\n",
      "LGB모델 4번째 검증 precision:0.8185\n",
      "LGB 평균 precision: 0.7649876890811177\n"
     ]
    }
   ],
   "source": [
    "# LGBMClassifier\n",
    "gbm = LGBMClassifier(n_jobs=-1, random_state = 10)\n",
    "sk_gbm = cross_socre(gbm)\n",
    "for idx, score in enumerate(sk_gbm):\n",
    "    print(\"LGB모델 {0}번째 검증 precision:{1:.4f}\".format(idx,score))\n",
    "print(\"LGB 평균 precision:\", sk_gbm.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "de4030ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data_DF.drop(columns = \"target 순위\")\n",
    "y = data_DF[\"target 순위\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "80ec4279",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, random_state= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "16125c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optuna Lightgbm\n",
    "def gbm_objective (trial):\n",
    "    params ={\n",
    "            \"n_estimators\" : trial.suggest_int(\"n_estimators\", 100, 300),\n",
    "            \"learning_rate\" : trial.suggest_float(\"learning_rate\", 0.5, 1, step=0.1),\n",
    "            \"max_depth\" : trial.suggest_int(\"max_depth\", 1, 10),\n",
    "            \"min_child_samples\" : trial.suggest_int(\"min_child_samples\", 1, 10)\n",
    "             }\n",
    "    gbm = LGBMClassifier(n_jobs=-1, **params,random_state=1234)\n",
    "    score = cross_socre(gbm)\n",
    "    gbm_score = score.mean()\n",
    "    return gbm_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "d3097f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-18 15:58:46,912]\u001b[0m A new study created in memory with name: no-name-74a3cd49-de79-4543-a4e7-c3cd5f98b617\u001b[0m\n",
      "\u001b[32m[I 2022-11-18 15:58:51,108]\u001b[0m Trial 0 finished with value: 0.8026937690012688 and parameters: {'n_estimators': 233, 'learning_rate': 0.7, 'max_depth': 10, 'min_child_samples': 6}. Best is trial 0 with value: 0.8026937690012688.\u001b[0m\n",
      "\u001b[32m[I 2022-11-18 15:58:52,792]\u001b[0m Trial 1 finished with value: 0.7586220320833583 and parameters: {'n_estimators': 132, 'learning_rate': 0.7, 'max_depth': 5, 'min_child_samples': 5}. Best is trial 0 with value: 0.8026937690012688.\u001b[0m\n",
      "\u001b[32m[I 2022-11-18 15:58:56,828]\u001b[0m Trial 2 finished with value: 0.7853652689876807 and parameters: {'n_estimators': 259, 'learning_rate': 0.9, 'max_depth': 7, 'min_child_samples': 5}. Best is trial 0 with value: 0.8026937690012688.\u001b[0m\n",
      "\u001b[32m[I 2022-11-18 15:58:58,210]\u001b[0m Trial 3 finished with value: 0.7234635473860106 and parameters: {'n_estimators': 285, 'learning_rate': 0.6, 'max_depth': 3, 'min_child_samples': 2}. Best is trial 0 with value: 0.8026937690012688.\u001b[0m\n",
      "\u001b[32m[I 2022-11-18 15:58:59,039]\u001b[0m Trial 4 finished with value: 0.5305127068557919 and parameters: {'n_estimators': 267, 'learning_rate': 0.7, 'max_depth': 1, 'min_child_samples': 9}. Best is trial 0 with value: 0.8026937690012688.\u001b[0m\n",
      "\u001b[32m[I 2022-11-18 15:58:59,736]\u001b[0m Trial 5 finished with value: 0.5928605860049244 and parameters: {'n_estimators': 163, 'learning_rate': 0.9, 'max_depth': 2, 'min_child_samples': 10}. Best is trial 0 with value: 0.8026937690012688.\u001b[0m\n",
      "\u001b[32m[I 2022-11-18 15:59:00,559]\u001b[0m Trial 6 finished with value: 0.6516841547134007 and parameters: {'n_estimators': 124, 'learning_rate': 0.7, 'max_depth': 3, 'min_child_samples': 9}. Best is trial 0 with value: 0.8026937690012688.\u001b[0m\n",
      "\u001b[32m[I 2022-11-18 15:59:02,712]\u001b[0m Trial 7 finished with value: 0.7770923872467179 and parameters: {'n_estimators': 154, 'learning_rate': 0.5, 'max_depth': 6, 'min_child_samples': 5}. Best is trial 0 with value: 0.8026937690012688.\u001b[0m\n",
      "\u001b[32m[I 2022-11-18 15:59:05,985]\u001b[0m Trial 8 finished with value: 0.7863441933613792 and parameters: {'n_estimators': 219, 'learning_rate': 1.0, 'max_depth': 8, 'min_child_samples': 5}. Best is trial 0 with value: 0.8026937690012688.\u001b[0m\n",
      "\u001b[32m[I 2022-11-18 15:59:08,473]\u001b[0m Trial 9 finished with value: 0.7802688797134631 and parameters: {'n_estimators': 169, 'learning_rate': 0.8, 'max_depth': 6, 'min_child_samples': 2}. Best is trial 0 with value: 0.8026937690012688.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# optuna study\n",
    "gbm_study = optuna.create_study(direction = \"maximize\")\n",
    "gbm_study.optimize(gbm_objective, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "43bb6fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value : [0.8026937690012688]\n",
      "params : {'n_estimators': 233, 'learning_rate': 0.7, 'max_depth': 10, 'min_child_samples': 6}\n"
     ]
    }
   ],
   "source": [
    "# 최적의 values 및 params\n",
    "print(\"value :\", gbm_study.best_trial.values)\n",
    "print(\"params :\", gbm_study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "37ee1480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMRegressor : 0.6866585067319462\n"
     ]
    }
   ],
   "source": [
    "# optuna\n",
    "gbm = LGBMClassifier(n_jobs=-1,\n",
    "                    n_estimators = 219,\n",
    "                    learning_rate = 0.5,\n",
    "                    max_depth = 10,\n",
    "                    min_child_samples = 9,\n",
    "                    random_state = 1234,\n",
    "                          )\n",
    "gbm.fit(X_train, y_train)\n",
    "gbm_study_ypred = gbm.predict(X_test)\n",
    "print(\"LGBMRegressor :\", precision_score(gbm_study_ypred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "9f8c39fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_path = \"real_df(classifier).csv\"\n",
    "real_df = pd.read_csv(real_path, encoding=\"cp949\")\n",
    "real_df.drop(columns = \"Unnamed: 0\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "3a077e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "racing_1 = real_df[real_df[\"경주번호\"] == 2022111311]\n",
    "racing_2 = real_df[real_df[\"경주번호\"] == 202211135]\n",
    "racing_3 = real_df[real_df[\"경주번호\"] == 2022111210]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "f6e8ecae",
   "metadata": {},
   "outputs": [],
   "source": [
    "racing_1 = racing_1.drop(columns = \"경주번호\", axis=1)\n",
    "racing_2 = racing_2.drop(columns = \"경주번호\", axis=1)\n",
    "racing_3 = racing_3.drop(columns = \"경주번호\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "16d2fb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF 정밀도: 1.000\n",
      "예측 : [1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0]\n",
      "실제 : [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# 1경기 \n",
    "X_Real_horse_1 = racing_1.drop(columns =[\"target 순위\"])\n",
    "y_Real_horse_1 = racing_1[\"target 순위\"]\n",
    "\n",
    "# 1경기 수정\n",
    "new_1_rf = pd.DataFrame(opt_xgbc.predict_proba(X_Real_horse_1))\n",
    "new_1_rf[\"y\"] = gbm.predict(X_Real_horse_1)\n",
    "new_1_rf[\"y\"]  = new_1_rf[0].apply(lambda x : 1 if x > 0.9 else 0)\n",
    "\n",
    "# 1경기 모델 \n",
    "score = precision_score(new_1_rf[\"y\"], y_Real_horse_1)\n",
    "print('RF 정밀도: {score:.3f}'.format(score=score))\n",
    "print(\"예측 :\", list(new_1_rf[\"y\"]))\n",
    "print(\"실제 :\", list(y_Real_horse_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "8c77f60b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.96752179, 0.03247821, 1.        ],\n",
       "       [0.96414453, 0.03585546, 1.        ],\n",
       "       [0.98816001, 0.01183998, 1.        ],\n",
       "       [0.72009754, 0.27990249, 0.        ],\n",
       "       [0.88851017, 0.11148982, 0.        ],\n",
       "       [0.91069603, 0.08930398, 1.        ],\n",
       "       [0.79159111, 0.20840888, 0.        ],\n",
       "       [0.86727172, 0.13272826, 0.        ],\n",
       "       [0.75382328, 0.2461767 , 0.        ],\n",
       "       [0.9107694 , 0.08923061, 1.        ],\n",
       "       [0.62269926, 0.37730071, 0.        ],\n",
       "       [0.65799272, 0.34200728, 0.        ]])"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(new_1_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "6c26e39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  XGB_Model 클래스 값 예측\n",
      " [[9.99615164e-01 3.84836026e-04 0.00000000e+00]\n",
      " [9.98903707e-01 1.09629293e-03 0.00000000e+00]\n",
      " [9.83131615e-01 1.68683849e-02 0.00000000e+00]\n",
      " [6.83289525e-01 3.16710475e-01 0.00000000e+00]\n",
      " [1.28003856e-01 8.71996144e-01 1.00000000e+00]\n",
      " [9.30953365e-01 6.90466354e-02 0.00000000e+00]\n",
      " [7.62203071e-01 2.37796929e-01 0.00000000e+00]\n",
      " [9.22952448e-01 7.70475518e-02 0.00000000e+00]\n",
      " [8.42378003e-01 1.57621997e-01 0.00000000e+00]\n",
      " [9.62300780e-01 3.76992198e-02 0.00000000e+00]\n",
      " [9.85021962e-01 1.49780379e-02 0.00000000e+00]\n",
      " [9.71493223e-01 2.85067770e-02 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# 예측 확률 proba \n",
    "pred_proba = gbm.predict_proba(X_Real_horse_1)\n",
    "pred = gbm.predict(X_Real_horse_1)\n",
    "pred_proba_result = np.concatenate([pred_proba, pred.reshape(-1,1)],axis=1)\n",
    "print('  XGB_Model 클래스 값 예측\\n',pred_proba_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "e0e2dda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF 정밀도: 1.000\n",
      "예측 : [1, 1, 1, 0, 0, 1, 0, 0, 0]\n",
      "실제 : [1, 1, 1, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# 2경기 \n",
    "X_Real_horse_2 = racing_2.drop(columns =[\"target 순위\"])\n",
    "y_Real_horse_2 = racing_2[\"target 순위\"]\n",
    "\n",
    "# 2경기 수정\n",
    "new_2_rf = pd.DataFrame(rf_model.predict_proba(X_Real_horse_2))\n",
    "new_2_rf[\"y\"] = rf_model.predict(X_Real_horse_2)\n",
    "new_2_rf[\"y\"]  = new_1_rf[0].apply(lambda x : 1 if x > 0.9 else 0)\n",
    "\n",
    "# 2경기 모델 \n",
    "score = precision_score(new_2_rf[\"y\"], y_Real_horse_2)\n",
    "print('RF 정밀도: {score:.3f}'.format(score=score))\n",
    "print(\"예측 :\", list(new_2_rf[\"y\"]))\n",
    "print(\"실제 :\", list(y_Real_horse_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "80ce341c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.967522</td>\n",
       "      <td>0.032478</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.964145</td>\n",
       "      <td>0.035855</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.988160</td>\n",
       "      <td>0.011840</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.720098</td>\n",
       "      <td>0.279902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.888510</td>\n",
       "      <td>0.111490</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.910696</td>\n",
       "      <td>0.089304</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.791591</td>\n",
       "      <td>0.208409</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.867272</td>\n",
       "      <td>0.132728</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.753823</td>\n",
       "      <td>0.246177</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.910769</td>\n",
       "      <td>0.089231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.622699</td>\n",
       "      <td>0.377301</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.657993</td>\n",
       "      <td>0.342007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1  y\n",
       "0   0.967522  0.032478  1\n",
       "1   0.964145  0.035855  1\n",
       "2   0.988160  0.011840  1\n",
       "3   0.720098  0.279902  0\n",
       "4   0.888510  0.111490  0\n",
       "5   0.910696  0.089304  1\n",
       "6   0.791591  0.208409  0\n",
       "7   0.867272  0.132728  0\n",
       "8   0.753823  0.246177  0\n",
       "9   0.910769  0.089231  1\n",
       "10  0.622699  0.377301  0\n",
       "11  0.657993  0.342007  0"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_1_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "3791a012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF 정밀도: 1.000\n",
      "예측 : [1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0]\n",
      "실제 : [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# 3경기 \n",
    "X_Real_horse_3 = racing_3.drop(columns =[\"target 순위\"])\n",
    "y_Real_horse_3 = racing_3[\"target 순위\"]\n",
    "\n",
    "# 3경기 수정\n",
    "new_3_rf = pd.DataFrame(rf_model.predict_proba(X_Real_horse_3))\n",
    "new_3_rf[\"y\"] = rf_model.predict(X_Real_horse_3)\n",
    "new_3_rf[\"y\"]  = new_1_rf[0].apply(lambda x : 1 if x > 0.9 else 0)\n",
    "\n",
    "# 3경기 모델 \n",
    "score = precision_score(new_3_rf[\"y\"], y_Real_horse_3)\n",
    "print('RF 정밀도: {score:.3f}'.format(score=score))\n",
    "print(\"예측 :\", list(new_3_rf[\"y\"]))\n",
    "print(\"실제 :\", list(y_Real_horse_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f09df81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cb9aa5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
